{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9 documents.\n",
      "\n",
      "Dictionary and corpus created.\n",
      "\n",
      "LDA model with 4 topics applied.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Topic   40 non-null     int64  \n",
      " 1   Word    40 non-null     object \n",
      " 2   Weight  40 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Word</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>course</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>student</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>data</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>class</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>policy</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>university</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>text</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>work</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>project</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>mining</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>student</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>course</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>class</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>data</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>work</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>week</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>http</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>university</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>http</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>course</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>language</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>processing</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>student</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>work</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>class</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>text</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>file</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>data</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>course</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>student</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>class</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>work</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>question</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>assignment</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>homework</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>week</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic        Word  Weight\n",
       "0       0      course   0.020\n",
       "1       0     student   0.019\n",
       "2       0        data   0.016\n",
       "3       0       class   0.015\n",
       "4       0        http   0.011\n",
       "5       0      policy   0.010\n",
       "6       0  university   0.009\n",
       "7       0        text   0.008\n",
       "8       0        work   0.008\n",
       "9       0     project   0.007\n",
       "10      1        text   0.002\n",
       "11      1      mining   0.001\n",
       "12      1     student   0.001\n",
       "13      1      course   0.001\n",
       "14      1       class   0.001\n",
       "15      1        data   0.001\n",
       "16      1        work   0.001\n",
       "17      1        week   0.001\n",
       "18      1        http   0.001\n",
       "19      1  university   0.001\n",
       "20      2        http   0.020\n",
       "21      2      course   0.015\n",
       "22      2    language   0.012\n",
       "23      2  processing   0.011\n",
       "24      2     student   0.010\n",
       "25      2   gutenberg   0.010\n",
       "26      2        work   0.009\n",
       "27      2       class   0.009\n",
       "28      2        text   0.009\n",
       "29      2        file   0.009\n",
       "30      3        data   0.030\n",
       "31      3      course   0.015\n",
       "32      3     student   0.012\n",
       "33      3       class   0.011\n",
       "34      3        work   0.010\n",
       "35      3    analysis   0.009\n",
       "36      3    question   0.008\n",
       "37      3  assignment   0.007\n",
       "38      3    homework   0.007\n",
       "39      3        week   0.007"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora, models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Import directory paths from secret config file\n",
    "from config import text_directory\n",
    "\n",
    "# Download NLTK resources (this can be done outside the functions, as a setup step)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "# Removes stopwords, lemmatizes, and cleans document text\n",
    "def preprocess(document):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = re.sub(r'\\W+', ' ', document.lower()).split()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and token.isalpha() and len(token) > 3]\n",
    "    return tokens\n",
    "\n",
    "# Loads and preprocesses all documents from a given directory\n",
    "def load_documents(directory):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            documents.append(preprocess(file.read()))\n",
    "    return documents\n",
    "\n",
    "# Creates a dictionary and corpus from preprocessed documents for LDA analysis\n",
    "def create_dictionary_corpus(documents):\n",
    "    dictionary = corpora.Dictionary(documents)\n",
    "    corpus = [dictionary.doc2bow(text) for text in documents]\n",
    "    return dictionary, corpus\n",
    "\n",
    "# Builds and returns an LDA model from the corpus and dictionary\n",
    "def apply_lda_model(corpus, dictionary, num_topics=4):\n",
    "    lda_model = gensim.models.LdaMulticore(corpus, num_topics=num_topics, id2word=dictionary, passes=10, workers=2)\n",
    "    return lda_model\n",
    "\n",
    "# Extracts and formats topics and their respective words and weights from the LDA model\n",
    "def extract_topics(lda_model):\n",
    "    def parse_topic_words(topic_str):\n",
    "        word_weight_pairs = topic_str.split(' + ')\n",
    "        parsed_pairs = [pair.split('*') for pair in word_weight_pairs]\n",
    "        return [(float(weight.strip()), word.strip('\"')) for weight, word in parsed_pairs]\n",
    "\n",
    "    topic_data = []\n",
    "    for idx, topic in lda_model.print_topics(-1):\n",
    "        for weight, word in parse_topic_words(topic):\n",
    "            topic_data.append([idx, word, weight])\n",
    "\n",
    "    topic_df = pd.DataFrame(topic_data, columns=['Topic', 'Word', 'Weight'])\n",
    "    return topic_df.sort_values(by=['Topic', 'Weight'], ascending=[True, False])\n",
    "\n",
    "# Calculates and returns the coherence score of the LDA model\n",
    "def calculate_coherence(lda_model, documents, dictionary):\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=documents, dictionary=dictionary, coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "# Prepares data for visualization of the LDA model\n",
    "def prepare_visualization(lda_model, corpus, dictionary):\n",
    "    return gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "\n",
    "# Load and preprocess documents\n",
    "documents = load_documents(text_directory)\n",
    "print(f\"Loaded {len(documents)} documents.\\n\")\n",
    "\n",
    "# Create dictionary and corpus\n",
    "dictionary, corpus = create_dictionary_corpus(documents)\n",
    "print(\"Dictionary and corpus created.\\n\")\n",
    "\n",
    "# Apply LDA model\n",
    "num_topics = 4\n",
    "lda_model = apply_lda_model(corpus, dictionary, num_topics)\n",
    "print(f\"LDA model with {num_topics} topics applied.\\n\")\n",
    "\n",
    "# Extract topics\n",
    "topic_df = extract_topics(lda_model)\n",
    "print(topic_df.info())\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic        Word  Weight\n",
      "0      0      course   0.020\n",
      "1      0     student   0.019\n",
      "2      0        data   0.016\n",
      "3      0       class   0.015\n",
      "4      0        http   0.011\n",
      "5      0      policy   0.010\n",
      "6      0  university   0.009\n",
      "7      0        text   0.008\n",
      "8      0        work   0.008\n",
      "9      0     project   0.007\n",
      "\n",
      "    Topic        Word  Weight\n",
      "10      1        text   0.002\n",
      "11      1      mining   0.001\n",
      "12      1     student   0.001\n",
      "13      1      course   0.001\n",
      "14      1       class   0.001\n",
      "15      1        data   0.001\n",
      "16      1        work   0.001\n",
      "17      1        week   0.001\n",
      "18      1        http   0.001\n",
      "19      1  university   0.001\n",
      "\n",
      "    Topic        Word  Weight\n",
      "20      2        http   0.020\n",
      "21      2      course   0.015\n",
      "22      2    language   0.012\n",
      "23      2  processing   0.011\n",
      "24      2     student   0.010\n",
      "25      2   gutenberg   0.010\n",
      "26      2        work   0.009\n",
      "27      2       class   0.009\n",
      "28      2        text   0.009\n",
      "29      2        file   0.009\n",
      "\n",
      "    Topic        Word  Weight\n",
      "30      3        data   0.030\n",
      "31      3      course   0.015\n",
      "32      3     student   0.012\n",
      "33      3       class   0.011\n",
      "34      3        work   0.010\n",
      "35      3    analysis   0.009\n",
      "36      3    question   0.008\n",
      "37      3  assignment   0.007\n",
      "38      3    homework   0.007\n",
      "39      3        week   0.007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by topic\n",
    "groups = topic_df.groupby('Topic')\n",
    "topic_dfs = {}\n",
    "\n",
    "for topic, group in groups:\n",
    "    topic_dfs[topic] = group\n",
    "\n",
    "for t in topic_dfs.keys():\n",
    "    print(f'{topic_dfs[t]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence score: 0.31385289848248316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate coherence\n",
    "coherence_score = calculate_coherence(lda_model, documents, dictionary)\n",
    "print(f\"Coherence score: {coherence_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3     -0.040804  0.064185       1        1  52.387989\n",
       "0     -0.078861  0.002425       2        1  33.234427\n",
       "2      0.002168 -0.092229       3        1  14.363213\n",
       "1      0.117497  0.025619       4        1   0.014370, topic_info=            Term        Freq       Total Category  logprob  loglift\n",
       "290         http  117.000000  117.000000  Default  30.0000  30.0000\n",
       "583         text   72.000000   72.000000  Default  29.0000  29.0000\n",
       "329     language   39.000000   39.000000  Default  28.0000  28.0000\n",
       "453   processing   39.000000   39.000000  Default  27.0000  27.0000\n",
       "155         data  336.000000  336.000000  Default  26.0000  26.0000\n",
       "...          ...         ...         ...      ...      ...      ...\n",
       "336     learning    0.001188   47.894081   Topic4  -7.5496  -1.7571\n",
       "571     syllabus    0.001206   72.336923   Topic4  -7.5345  -2.1543\n",
       "1151    exercise    0.001122   23.308585   Topic4  -7.6062  -1.0935\n",
       "25          also    0.001149   43.593940   Topic4  -7.5825  -1.6958\n",
       "406       online    0.001150   47.182659   Topic4  -7.5816  -1.7741\n",
       "\n",
       "[336 rows x 6 columns], token_table=      Topic      Freq           Term\n",
       "term                                \n",
       "4         1  0.440122       academic\n",
       "4         2  0.427177       academic\n",
       "4         3  0.129448       academic\n",
       "10        1  0.292852  accommodation\n",
       "10        2  0.608231  accommodation\n",
       "...     ...       ...            ...\n",
       "633       3  0.148673           work\n",
       "1383      1  0.953707          write\n",
       "1383      2  0.036681          write\n",
       "2165      3  0.700837          wrong\n",
       "1293      2  0.648540          zhang\n",
       "\n",
       "[413 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 3, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply prepare_visualization function\n",
    "prepare_visualization(lda_model, corpus, dictionary)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
